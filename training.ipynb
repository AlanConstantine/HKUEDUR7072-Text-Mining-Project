{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = list(range(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>afraid</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>ah</th>\n",
       "      <th>ai</th>\n",
       "      <th>aint</th>\n",
       "      <th>air</th>\n",
       "      <th>aliv</th>\n",
       "      <th>alon</th>\n",
       "      <th>...</th>\n",
       "      <th>x2</th>\n",
       "      <th>ya</th>\n",
       "      <th>ye</th>\n",
       "      <th>yea</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035947</td>\n",
       "      <td>0.188197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   act  afraid  age  ago   ah       ai  aint       air      aliv      alon  \\\n",
       "0  0.0     0.0  0.0  0.0  0.0  0.00000   0.0  0.000000  0.028271  0.000000   \n",
       "1  0.0     0.0  0.0  0.0  0.0  0.00000   0.0  0.000000  0.000000  0.000000   \n",
       "2  0.0     0.0  0.0  0.0  0.0  0.00000   0.0  0.000000  0.085668  0.000000   \n",
       "3  0.0     0.0  0.0  0.0  0.0  0.03901   0.0  0.254412  0.000000  0.000000   \n",
       "4  0.0     0.0  0.0  0.0  0.0  0.00000   0.0  0.000000  0.000000  0.216461   \n",
       "\n",
       "   ...   x2   ya        ye  yea      yeah      year  yesterday   yo     young  \\\n",
       "0  ...  0.0  0.0  0.000000  0.0  0.000000  0.000000        0.0  0.0  0.000000   \n",
       "1  ...  0.0  0.0  0.000000  0.0  0.000000  0.000000        0.0  0.0  0.000000   \n",
       "2  ...  0.0  0.0  0.000000  0.0  0.000000  0.000000        0.0  0.0  0.000000   \n",
       "3  ...  0.0  0.0  0.100178  0.0  0.035947  0.188197        0.0  0.0  0.027036   \n",
       "4  ...  0.0  0.0  0.000000  0.0  0.000000  0.000000        0.0  0.0  0.000000   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  \n",
       "\n",
       "[5 rows x 789 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'./df_tfidf4395.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 8.5776640097168\n",
      "3 7.602568532441171\n",
      "4 6.5123734239046405\n",
      "5 7.860200282523778\n",
      "6 7.593222031160148\n",
      "7 7.236792062867887\n",
      "8 6.571751734390039\n",
      "9 6.643355777503522\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=905).fit(data)\n",
    "    labels = kmeans.labels_\n",
    "    results[k] = {\n",
    "                  'db_index': davies_bouldin_score(data, labels),\n",
    "                  'labels': kmeans.labels_,\n",
    "                  'centres': kmeans.cluster_centers_\n",
    "                 }\n",
    "    print(k, davies_bouldin_score(data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=4, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=905)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.418s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "lda.fit(data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: la holi da shall prais glori mr bore lord king hi born power chain fame lil luck ooh sing high\n",
      "Topic #1: dem doll di wild escap lone choru quick check like war say bout heart want deep day man come da\n",
      "Topic #2: thou brown touch suck hot gold kill burn great fuck murder bag woah feel tree love bird deeper need wit\n",
      "Topic #3: love know like got ll time ve oh come want na let say feel make way babi ca day life\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, features, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./lyrics_emotion[0-7480].json', 'r') as fn:\n",
    "    emo_dict = json.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>word_count</th>\n",
       "      <th>represent</th>\n",
       "      <th>represent_2nd</th>\n",
       "      <th>word_count_2nd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>louder-flux-pavilion-doctor-p-remix</td>\n",
       "      <td>2012</td>\n",
       "      <td>dj-fresh</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>I can't control this feeling Something's happe...</td>\n",
       "      <td>341.0</td>\n",
       "      <td>I ca n't control feel someth 's happen insid o...</td>\n",
       "      <td>I ca n't control feel someth 's happen insid s...</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>that-s-my-name</td>\n",
       "      <td>2009</td>\n",
       "      <td>akcent</td>\n",
       "      <td>Pop</td>\n",
       "      <td>In my heart I will keep you In my heart Foreve...</td>\n",
       "      <td>318.0</td>\n",
       "      <td>In heart I keep In heart forev In heart and on...</td>\n",
       "      <td>In heart I keep In heart forev In heart one li...</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>lemonade</td>\n",
       "      <td>2007</td>\n",
       "      <td>apologetix</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Oh, Mama, I've been cleared of my crimes and I...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Oh mama I 've clear crime I 'm law law put end...</td>\n",
       "      <td>Oh mama I 've clear crime I 'm law law put end...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>return-of-the-hustle</td>\n",
       "      <td>2007</td>\n",
       "      <td>fabolous</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Record mode! (Record mode!) Get your money in ...</td>\n",
       "      <td>681.0</td>\n",
       "      <td>record mode record mode get money air like yea...</td>\n",
       "      <td>record record get money air like yeah yeah tim...</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>so-sad</td>\n",
       "      <td>1974</td>\n",
       "      <td>george-harrison</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Now the winter has come To eclipse out the sun...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>now winter come To eclips sun that light love ...</td>\n",
       "      <td>winter come To sun light love sometim cold win...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                 song  year           artist  \\\n",
       "0      0  louder-flux-pavilion-doctor-p-remix  2012         dj-fresh   \n",
       "1      1                       that-s-my-name  2009           akcent   \n",
       "2      2                             lemonade  2007       apologetix   \n",
       "3      3                 return-of-the-hustle  2007         fabolous   \n",
       "4      4                               so-sad  1974  george-harrison   \n",
       "\n",
       "        genre                                             lyrics  word_count  \\\n",
       "0  Electronic  I can't control this feeling Something's happe...       341.0   \n",
       "1         Pop  In my heart I will keep you In my heart Foreve...       318.0   \n",
       "2        Rock  Oh, Mama, I've been cleared of my crimes and I...       250.0   \n",
       "3     Hip-Hop  Record mode! (Record mode!) Get your money in ...       681.0   \n",
       "4        Rock  Now the winter has come To eclipse out the sun...       163.0   \n",
       "\n",
       "                                           represent  \\\n",
       "0  I ca n't control feel someth 's happen insid o...   \n",
       "1  In heart I keep In heart forev In heart and on...   \n",
       "2  Oh mama I 've clear crime I 'm law law put end...   \n",
       "3  record mode record mode get money air like yea...   \n",
       "4  now winter come To eclips sun that light love ...   \n",
       "\n",
       "                                       represent_2nd  word_count_2nd  \n",
       "0  I ca n't control feel someth 's happen insid s...             339  \n",
       "1  In heart I keep In heart forev In heart one li...             169  \n",
       "2  Oh mama I 've clear crime I 'm law law put end...             119  \n",
       "3  record record get money air like yeah yeah tim...             338  \n",
       "4  winter come To sun light love sometim cold win...              72  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cls = pd.read_csv('./df_4395.csv')\n",
    "data_cls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>word_count</th>\n",
       "      <th>represent</th>\n",
       "      <th>represent_2nd</th>\n",
       "      <th>word_count_2nd</th>\n",
       "      <th>clustered_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>louder-flux-pavilion-doctor-p-remix</td>\n",
       "      <td>2012</td>\n",
       "      <td>dj-fresh</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>I can't control this feeling Something's happe...</td>\n",
       "      <td>341.0</td>\n",
       "      <td>I ca n't control feel someth 's happen insid o...</td>\n",
       "      <td>I ca n't control feel someth 's happen insid s...</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>that-s-my-name</td>\n",
       "      <td>2009</td>\n",
       "      <td>akcent</td>\n",
       "      <td>Pop</td>\n",
       "      <td>In my heart I will keep you In my heart Foreve...</td>\n",
       "      <td>318.0</td>\n",
       "      <td>In heart I keep In heart forev In heart and on...</td>\n",
       "      <td>In heart I keep In heart forev In heart one li...</td>\n",
       "      <td>169</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>lemonade</td>\n",
       "      <td>2007</td>\n",
       "      <td>apologetix</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Oh, Mama, I've been cleared of my crimes and I...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Oh mama I 've clear crime I 'm law law put end...</td>\n",
       "      <td>Oh mama I 've clear crime I 'm law law put end...</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>return-of-the-hustle</td>\n",
       "      <td>2007</td>\n",
       "      <td>fabolous</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Record mode! (Record mode!) Get your money in ...</td>\n",
       "      <td>681.0</td>\n",
       "      <td>record mode record mode get money air like yea...</td>\n",
       "      <td>record record get money air like yeah yeah tim...</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>so-sad</td>\n",
       "      <td>1974</td>\n",
       "      <td>george-harrison</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Now the winter has come To eclipse out the sun...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>now winter come To eclips sun that light love ...</td>\n",
       "      <td>winter come To sun light love sometim cold win...</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                 song  year           artist  \\\n",
       "0      0  louder-flux-pavilion-doctor-p-remix  2012         dj-fresh   \n",
       "1      1                       that-s-my-name  2009           akcent   \n",
       "2      2                             lemonade  2007       apologetix   \n",
       "3      3                 return-of-the-hustle  2007         fabolous   \n",
       "4      4                               so-sad  1974  george-harrison   \n",
       "\n",
       "        genre                                             lyrics  word_count  \\\n",
       "0  Electronic  I can't control this feeling Something's happe...       341.0   \n",
       "1         Pop  In my heart I will keep you In my heart Foreve...       318.0   \n",
       "2        Rock  Oh, Mama, I've been cleared of my crimes and I...       250.0   \n",
       "3     Hip-Hop  Record mode! (Record mode!) Get your money in ...       681.0   \n",
       "4        Rock  Now the winter has come To eclipse out the sun...       163.0   \n",
       "\n",
       "                                           represent  \\\n",
       "0  I ca n't control feel someth 's happen insid o...   \n",
       "1  In heart I keep In heart forev In heart and on...   \n",
       "2  Oh mama I 've clear crime I 'm law law put end...   \n",
       "3  record mode record mode get money air like yea...   \n",
       "4  now winter come To eclips sun that light love ...   \n",
       "\n",
       "                                       represent_2nd  word_count_2nd  \\\n",
       "0  I ca n't control feel someth 's happen insid s...             339   \n",
       "1  In heart I keep In heart forev In heart one li...             169   \n",
       "2  Oh mama I 've clear crime I 'm law law put end...             119   \n",
       "3  record record get money air like yeah yeah tim...             338   \n",
       "4  winter come To sun light love sometim cold win...              72   \n",
       "\n",
       "   clustered_label  \n",
       "0                3  \n",
       "1                2  \n",
       "2                2  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cls['clustered_label'] = pd.Series(results[4]['labels'])\n",
    "data_cls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Fear',\n",
    "            'Sad',\n",
    "            'Bored',\n",
    "            'Happy',\n",
    "            'Excited',\n",
    "            'Angry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1002.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(emotions):\n",
    "    data_cls[e] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4395/4395 [00:06<00:00, 663.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data_cls))):\n",
    "    lyrics_emotion = emo_dict[str(i)]['emotion']\n",
    "    values = [lyrics_emotion[e] for e in emotions]\n",
    "    data_cls.at[i, emotions] = values\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(ypred, ytest):\n",
    "    return f1_score(ypred, ytest, average='micro'), cohen_kappa_score(ypred, ytest)\n",
    "\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "scoring = kappa_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(xtrain, xtest, ytrain, ytest, batch):\n",
    "    t0 = time()\n",
    "    param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], \n",
    "                 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), param_grid, scoring=scoring\n",
    "    )\n",
    "    searcher = clf.fit(xtrain, ytrain)\n",
    "    estimator = searcher.best_estimator_\n",
    "    f1, kappa = measures(estimator.predict(xtest), ytest)\n",
    "    print('[SVM] training: ', 'f1:', f1, 'kappa:', kappa, \"done in %0.3fs.\" % (time() - t0))\n",
    "    with open(batch + '_svm_clf.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    with open(batch + '_svm_searcher.pickle',\n",
    "              'wb') as sf:\n",
    "        pickle.dump(searcher, sf)\n",
    "    with open(batch + '_svm_estimator.pickle',\n",
    "      'wb') as sfm:\n",
    "        pickle.dump(estimator, sfm)\n",
    "    return searcher, estimator, clf, f1, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_model(xtrain, xtest, ytrain, ytest, batch):\n",
    "    t0 = time()\n",
    "    param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                  'max_iter': range(10, 50, 10)}\n",
    "    clf = GridSearchCV(\n",
    "        LogisticRegression(multi_class='auto', n_jobs=-1), param_grid, scoring=scoring\n",
    "    )\n",
    "    searcher = clf.fit(xtrain, ytrain)\n",
    "    estimator = searcher.best_estimator_\n",
    "    f1, kappa = measures(estimator.predict(xtest), ytest)\n",
    "    print('[LG] training: ', 'f1:', f1, 'kappa:', kappa, \"done in %0.3fs.\" % (time() - t0))\n",
    "    with open(batch + '_lg_clf.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    with open(batch + '_lg_searcher.pickle',\n",
    "              'wb') as sf:\n",
    "        pickle.dump(searcher, sf)\n",
    "    with open(batch + '_lg_estimator.pickle',\n",
    "      'wb') as sfm:\n",
    "        pickle.dump(estimator, sfm)\n",
    "    return searcher, estimator, clf, f1, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_model(xtrain, xtest, ytrain, ytest, batch):\n",
    "    t0 = time()\n",
    "    param_grid = {'min_samples_split': range(2, 403, 20)}\n",
    "    clf = GridSearchCV(\n",
    "        tree.DecisionTreeClassifier(), param_grid, scoring=scoring\n",
    "    )\n",
    "    searcher = clf.fit(xtrain, ytrain)\n",
    "    estimator = searcher.best_estimator_\n",
    "    f1, kappa = measures(estimator.predict(xtest), ytest)\n",
    "    print('[dt] training: ', 'f1:', f1, 'kappa:', kappa, \"done in %0.3fs.\" % (time() - t0))\n",
    "    with open(batch + '_dt_clf.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    with open(batch + '_dt_searcher.pickle',\n",
    "              'wb') as sf:\n",
    "        pickle.dump(searcher, sf)\n",
    "    with open(batch + '_dt_estimator.pickle',\n",
    "      'wb') as sfm:\n",
    "        pickle.dump(estimator, sfm)\n",
    "    return searcher, estimator, clf, f1, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_model(xtrain, xtest, ytrain, ytest, batch):\n",
    "    t0 = time()\n",
    "    param_grid = {}\n",
    "    clf = GridSearchCV(GaussianNB(), param_grid)\n",
    "    searcher = clf.fit(xtrain, ytrain)\n",
    "    estimator = searcher.best_estimator_\n",
    "    f1, kappa = measures(estimator.predict(xtest), ytest)\n",
    "    print('[NB] training: ', 'f1:', f1, 'kappa:', kappa, \"done in %0.3fs.\" % (time() - t0))\n",
    "    with open(batch + '_nb_clf.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    with open(batch + '_nb_searcher.pickle',\n",
    "              'wb') as sf:\n",
    "        pickle.dump(searcher, sf)\n",
    "    with open(batch + '_nb_estimator.pickle',\n",
    "      'wb') as sfm:\n",
    "        pickle.dump(estimator, sfm)\n",
    "    return searcher, estimator, clf, f1, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(xtrain, xtest, ytrain, ytest, batch):\n",
    "    t0 = time()\n",
    "    hidden_layer_sizes = (10, 50, 50, 10)\n",
    "    param_grid = {\n",
    "                  'alpha': [1e-5, 1e-4, 1e-3],\n",
    "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                 }\n",
    "    if batch == 'lyrics':\n",
    "        hidden_layer_sizes=(100, 200, 100, 50)\n",
    "    clf = GridSearchCV(MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, random_state=905, early_stopping=True), param_grid)\n",
    "    searcher = clf.fit(xtrain, ytrain)\n",
    "    estimator = searcher.best_estimator_\n",
    "    f1, kappa = measures(estimator.predict(xtest), ytest)\n",
    "    print('[nn] training: ', 'f1:', f1, 'kappa:', kappa, \"done in %0.3fs.\" % (time() - t0))\n",
    "    with open(batch + '_nn_clf.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    with open(batch + '_nn_searcher.pickle',\n",
    "              'wb') as sf:\n",
    "        pickle.dump(searcher, sf)\n",
    "    with open(batch + '_nn_estimator.pickle',\n",
    "      'wb') as sfm:\n",
    "        pickle.dump(estimator, sfm)\n",
    "    return searcher, estimator, clf, f1, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock             1840\n",
       "Pop               657\n",
       "Hip-Hop           472\n",
       "Metal             368\n",
       "Not Available     325\n",
       "Country           283\n",
       "Electronic        135\n",
       "Jazz              110\n",
       "R&B                67\n",
       "Other              60\n",
       "Indie              54\n",
       "Folk               24\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cls['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {}\n",
    "count = 1\n",
    "for i in set(data_cls['genre'].tolist()):\n",
    "    target[i] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Folk': 1,\n",
       " 'Pop': 2,\n",
       " 'Country': 3,\n",
       " 'Other': 4,\n",
       " 'Electronic': 5,\n",
       " 'Jazz': 6,\n",
       " 'Hip-Hop': 7,\n",
       " 'Indie': 8,\n",
       " 'Not Available': 9,\n",
       " 'Metal': 10,\n",
       " 'R&B': 11,\n",
       " 'Rock': 12}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls['genre_'] = data_cls['genre']\n",
    "\n",
    "data_cls['genre'] = data_cls['genre'].map(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'song', 'year', 'artist', 'genre', 'lyrics', 'word_count',\n",
       "       'represent', 'represent_2nd', 'word_count_2nd', 'clustered_label',\n",
       "       'Fear', 'Sad', 'Bored', 'Happy', 'Excited', 'Angry', 'genre_'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cls.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion & Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3516, 7), (879, 7), (3516,), (879,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_cls[['clustered_label','Fear', 'Sad', 'Bored', 'Happy', 'Excited', 'Angry']].values\n",
    "Y = data_cls['genre'].astype(int).values\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=31)\n",
    "xtrain.shape, xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LG] training:  f1: 0.4641638225255973 kappa: 0.15662068923370254 done in 3.476s.\n",
      "[dt] training:  f1: 0.4061433447098976 kappa: 0.13125353822035324 done in 2.095s.\n",
      "[NB] training:  f1: 0.43913538111490324 kappa: 0.1412426355621348 done in 0.019s.\n"
     ]
    }
   ],
   "source": [
    "# nn_searcher, nn_estimator, nn_clf, nn_f1, nn_kappa = nn_model(xtrain, xtest, ytrain, ytest, batch='Combined')\n",
    "# svm_searcher, svm_estimator, svm_clf, svm_f1, svm_kappa = svm_model(xtrain, xtest, ytrain, ytest, batch='Combined')\n",
    "lg_searcher, lg_estimator, lg_clf, lg_f1, lg_kappa = lg_model(xtrain, xtest, ytrain, ytest, batch='Combined')\n",
    "dt_searcher, dt_estimator, dt_clf, dt_f1, dt_kappa = dt_model(xtrain, xtest, ytrain, ytest, batch='Combined')\n",
    "nb_searcher, nb_estimator, nb_clf, nb_f1, nb_kappa = nb_model(xtrain, xtest, ytrain, ytest, batch='Combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3516, 788), (879, 788), (3516,), (879,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = data\n",
    "Y_ = data_cls['genre'].astype(int).values\n",
    "\n",
    "xtrain_, xtest_, ytrain_, ytest_ = train_test_split(X_, Y_, test_size=0.2, random_state=31)\n",
    "xtrain_.shape, xtest_.shape, ytrain_.shape, ytest_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LG] training:  f1: 0.5164960182025028 kappa: 0.2754150252826477 done in 18.252s.\n",
      "[dt] training:  f1: 0.41069397042093286 kappa: 0.18626820219176898 done in 67.965s.\n",
      "[NB] training:  f1: 0.24118316268486917 kappa: 0.13869231865385823 done in 0.858s.\n"
     ]
    }
   ],
   "source": [
    "# nn_searcher_, nn_estimator_, nn_clf_, nn_f1_, nn_kappa_ = nn_model(xtrain_, xtest_, ytrain_, ytest_, batch='lyrics')\n",
    "# svm_searcher_, svm_estimator_, svm_clf_, svm_f1_, svm_kappa_ = svm_model(xtrain_, xtest_, ytrain_, ytest_, batch='lyrics')\n",
    "lg_searcher_, lg_estimator_, lg_clf_, lg_f1_, lg_kappa_ = lg_model(xtrain_, xtest_, ytrain_, ytest_, batch='lyrics')\n",
    "dt_searcher_, dt_estimator_, dt_clf_, dt_f1_, dt_kappa_ = dt_model(xtrain_, xtest_, ytrain_, ytest_, batch='lyrics')\n",
    "nb_searcher_, nb_estimator_, nb_clf_, nb_f1_, nb_kappa_ = nb_model(xtrain_, xtest_, ytrain_, ytest_, batch='lyrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(path):\n",
    "    models = {}\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for fn in files:\n",
    "            eachpath = str(root+'/'+fn)\n",
    "            if '.pickle' in eachpath:\n",
    "                print(eachpath)\n",
    "                models[fn.replace('.pickle', '')] = pickle.load(open(eachpath, 'rb'))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".//.gitignore\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '*'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-6f85c455c1c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodels_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'./'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-af416c8f4618>\u001b[0m in \u001b[0;36mload_models\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'searcher'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meachpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meachpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meachpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '*'."
     ]
    }
   ],
   "source": [
    "models_path = r'./'\n",
    "models = load_models(models_path)\n",
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0cfbcd6f21b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mevaluate_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'group_model_k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kappa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodels_10fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmodel_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_results = pd.DataFrame(columns=['group_model_k', 'f1', 'kappa'])\n",
    "models_10fold = []\n",
    "for model in list(models.keys()):\n",
    "    for i in range(1, 11):\n",
    "        model_i = model + '_' + str(i)\n",
    "        models_10fold.append(model_i)\n",
    "evaluate_results['group_model_k'] = pd.Series(list(models_10fold))\n",
    "evaluate_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
